import argparse
import sys
import os

import torch
from torch import nn, optim
from torch.utils.data import DataLoader

from torchvision import datasets, transforms, utils

from tqdm import tqdm

from models.vqvae2.vqvae import VQVAE, VQVAETop
from models.vqvae2.scheduler import CycleScheduler
import models.vqvae2.distributed as dist
from models.vqvae2.distributed.launch import launch

os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
# os.environ["CUDA_VISIBLE_DEVICES"] = "0,1,2,4"
os.environ["DEBUG"] = "False"

def train(epoch, loader, model, optimizer, scheduler, device, dataset):
    if dist.is_primary():
        loader = tqdm(loader)

    criterion = nn.MSELoss()

    latent_loss_weight = 0.25
    sample_size = 16

    mse_sum = 0
    mse_n = 0

    for i, (img, label) in enumerate(loader):
        model.zero_grad()

        img = img.to(device)

        out, latent_loss = model(img)
        recon_loss = criterion(out, img)
        latent_loss = latent_loss.mean()
        loss = recon_loss + latent_loss_weight * latent_loss
        loss.backward()

        if scheduler is not None:
            scheduler.step()
        optimizer.step()

        part_mse_sum = recon_loss.item() * img.shape[0]
        part_mse_n = img.shape[0]
        comm = {"mse_sum": part_mse_sum, "mse_n": part_mse_n}
        comm = dist.all_gather(comm)

        for part in comm:
            mse_sum += part["mse_sum"]
            mse_n += part["mse_n"]

        if dist.is_primary():
            lr = optimizer.param_groups[0]["lr"]

            loader.set_description(
                (
                    f"epoch: {epoch + 1}; mse: {recon_loss.item():.5f}; "
                    f"latent: {latent_loss.item():.3f}; avg mse: {mse_sum / mse_n:.5f}; "
                    f"lr: {lr:.5f}"
                )
            )

            if i % 100 == 0:
                model.eval()

                sample = img[:sample_size]

                with torch.no_grad():
                    out, _ = model(sample)

                utils.save_image(
                    torch.cat([sample, out], 0),
                    f"models/vqvae2/sample/%s/{str(epoch + 1).zfill(5)}_{str(i).zfill(5)}.png" % (dataset),
                    nrow=sample_size,
                    normalize=True,
                    range=(-1, 1),
                )

                model.train()

# Train for ARKit
# CUDA_VISIBLE_DEVICES=0,1 python train_vqvae.py --path ../ARKitScenes/Selected/rgb_train --n_gpu 2 --dataset arkit --epoch 100 --size 192 256

# CUDA_VISIBLE_DEVICES=9 python train_vqvae.py --path ../trevi_fountain/dense/distill_train --n_gpu 1 --dataset fountain --epoch 100 --size 384 512


def main(args):
    device = "cuda"

    args.distributed = dist.get_world_size() > 1

    size = args.size if len(args.size) == 1 else tuple(args.size)
    print(f'Image size: {size}.')
    transform = transforms.Compose(
        [
            transforms.Resize(size),
            transforms.CenterCrop(size),
            transforms.ToTensor(),
            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),
        ]
    )
    dataset = datasets.ImageFolder(args.path, transform=transform)
    sampler = dist.data_sampler(dataset, shuffle=True, distributed=args.distributed)
    loader = DataLoader(
        dataset, batch_size=8 // args.n_gpu, sampler=sampler, num_workers=0
    )

    model = VQVAETop().to(device)

    if args.distributed:
        model = nn.parallel.DistributedDataParallel(
            model,
            device_ids=[dist.get_local_rank()],
            output_device=dist.get_local_rank(),
        )

    optimizer = optim.Adam(model.parameters(), lr=args.lr)
    scheduler = None
    if args.sched == "cycle":
        scheduler = CycleScheduler(
            optimizer,
            args.lr,
            n_iter=len(loader) * args.epoch,
            momentum=None,
            warmup_proportion=0.05,
        )
    
    model.load_state_dict(torch.load('models/vqvae2/checkpoint/%s/vqvae_105.pt' % (args.dataset)))

    for i in range(105, args.epoch):
        train(i, loader, model, optimizer, scheduler, device, args.dataset)

        if dist.is_primary():
            torch.save(model.state_dict(), f"models/vqvae2/checkpoint/%s/vqvae_{str(i + 1).zfill(3)}.pt" % (args.dataset))


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--n_gpu", type=int, default=1)

    port = (
        2 ** 15
        + 2 ** 14
        + hash(os.getuid() if sys.platform != "win32" else 1) % 2 ** 14 + 1
    )
    parser.add_argument("--dist_url", default=f"tcp://127.0.0.1:{port}")

    parser.add_argument("--size", type=int, nargs='+', default=256)
    parser.add_argument("--epoch", type=int, default=150)
    parser.add_argument("--lr", type=float, default=3e-4)
    parser.add_argument("--sched", type=str)
    parser.add_argument("--path", type=str)
    parser.add_argument("--dataset", type=str)

    args = parser.parse_args()

    print(args)

    try:
        os.makedirs('models/vqvae2/sample/%s/' % (args.dataset))
    except:
        pass
    try:
        os.makedirs('models/vqvae2/checkpoint/%s/' % (args.dataset))
    except:
        pass

    # dist.launch(main, args.n_gpu, 1, 0, args.dist_url, args=(args,))
    launch(main, args.n_gpu, 1, 0, args.dist_url, args=(args,))
